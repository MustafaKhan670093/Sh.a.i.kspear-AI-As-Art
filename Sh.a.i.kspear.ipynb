{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generating Poetry.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MustafaKhan670093/Sh.a.i.kspear-AI-As-Art/blob/main/Sh.a.i.kspear.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87_eO5DcKL9d"
      },
      "source": [
        "## **Install Requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1l4Lo27Mp2T"
      },
      "source": [
        "!pip install transformers "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypMlaKBdNdCG"
      },
      "source": [
        "import transformers\n",
        "import torch"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqUNSr3YNkUV"
      },
      "source": [
        "# Load in GPT-2 using the transformers library\n",
        "gpt_tokenizer = transformers.GPT2Tokenizer.from_pretrained('gpt2-large')\n",
        "#Loading model\n",
        "gpt_model = transformers.GPT2LMHeadModel.from_pretrained('gpt2-large')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsGXWnNpKbei"
      },
      "source": [
        "## **Text Generation Function Using GPT-2**\n",
        "\n",
        "**Note:** `n_seqs` is the number of sentences to generate and `max_length` is the maximum length of the sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLHa_FKpOMhf"
      },
      "source": [
        "def gen_text(prompt_text, tokenizer, model, n_seqs=1, max_length=25):\n",
        "  \n",
        "  #Encoding text using the gpt tokenizer (output of type \"pt\" since we are using PyTorch) \n",
        "  encoded_prompt = tokenizer.encode(prompt_text, add_special_tokens=False, return_tensors=\"pt\")\n",
        " \n",
        "  #Feed encoded input into the model\n",
        "  output_sequences = model.generate(input_ids=encoded_prompt,\n",
        "                                    max_length=max_length+len(encoded_prompt), \n",
        "                                    temperature=1.0,\n",
        "                                    top_k=0,\n",
        "                                    top_p=0.9,\n",
        "                                    repetition_penalty=1.2, \n",
        "                                    do_sample=True,\n",
        "                                    num_return_sequences=n_seqs)\n",
        "  \n",
        "  #Getting the output \n",
        "  if len(output_sequences.shape) > 2:\n",
        "    output_sequences.squeeze_() # Note: the _ indicates that the operation will be done in-place\n",
        "  \n",
        "  generated_sequences = []\n",
        "\n",
        "  for generated_sequence_idx, generated_sequence in enumerate(output_sequences):\n",
        "    generated_sequence = generated_sequence.tolist()\n",
        "    text = tokenizer.decode(generated_sequence)\n",
        "    total_sequence = (prompt_text + text[len(tokenizer.decode(encoded_prompt[0], clean_up_tokenization_spaces=True, )) :])\n",
        "    generated_sequences.append(total_sequence)\n",
        "\n",
        "  return generated_sequences"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSnOxId2L3AA"
      },
      "source": [
        "## **Implementing Function To Generate Text**\n",
        "\n",
        "**Note:** Alter the sample input to the function, `max_length` of the output and the `n_seqs` generated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5NxLz6TBkVm"
      },
      "source": [
        "input_text = '''Through the ghoul-guarded gateways of slumber,\n",
        "Past the wan-mooned abysses of night,\n",
        "I have lived o'er my lives without number,\n",
        "I have sounded all things with my sight;\n",
        "And I struggle and shriek ere the daybreak, being driven to madness with fright.\n",
        "'''\n",
        "\n",
        "input_text2 = '''Can one ever prevent their end?\n",
        "Yet o’ great rooted oak you still show,\n",
        "Even though your leaves slowly descend,\n",
        "That mighty oaks from little acorns grow.\n",
        "'''\n",
        "\n",
        "input_text3 = '''I met a traveller from an antique land\n",
        "Who said: Two vast and trunkless legs of stone\n",
        "Stand in the desert. Near them, on the sand,\n",
        "Half sunk, a shattered visage lies, whose frown,\n",
        "And wrinkled lip, and sneer of cold command,\n",
        "Tell that its sculptor well those passions read\n",
        "Which yet survive, stamped on these lifeless things,\n",
        "The hand that mocked them and the heart that fed:\n",
        "And on the pedestal these words appear:\n",
        "'My name is Ozymandias, king of kings:\n",
        "Look on my works, ye Mighty, and despair!'\n",
        "Nothing beside remains. Round the decay\n",
        "Of that colossal wreck, boundless and bare\n",
        "The lone and level sands stretch far away'''\n",
        "\n",
        "input_text4 = '''Methinks I see her in her blissful dreams:\n",
        "Or, fancy-like, in some mirage she lies,\n",
        "Majestic yet majestic, and of seems\n",
        "The image of the unconquerable skies.'''\n",
        "\n",
        "input_text5 = '''To be, or not to be, that is the question:\n",
        "Whether 'tis nobler in the mind to suffer\n",
        "The slings and arrows of outrageous fortune,\n",
        "Or to take arms against a sea of troubles\n",
        "And by opposing end them. To die—to sleep,'''"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xPYhy5WQfWm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab0dfcc5-309a-42c7-a409-1cef3e4c025b"
      },
      "source": [
        "gen_text(input_text, gpt_tokenizer, gpt_model, max_length=300, n_seqs=1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Through the ghoul-guarded gateways of slumber,\\nPast the wan-mooned abysses of night,\\nI have lived o\\'er my lives without number,\\nI have sounded all things with my sight;\\nAnd I struggle and shriek ere the daybreak, being driven to madness with fright.\\nBecause of the moon—because of the moon\\'s reproachful gaze.\\nAmong its numerous eyes is her inmost eye.\"\\n\\n\\n11 Herean Toth spent his final days: he was buried alive on a highway road in Old England with small huts surrounding it, at least as near as we know at this point:\\n\\n\"And here I beheld, on a narrow track unkempt,\\n\\nA corpse unburied dross, dejected and wet.—Be not deceived! For face to face there is no strife\\n\\nThe washerman is thy father or yourself alive?.\\n\\nHe leads thee through an inscrutable maze of darkness,—which he hath cleared\\n\\nFor a headless holyhead which stands moving along under a solar moon.\\n\\nAs sudden, ecstatic and half starlighted as a throng of fairies enter into eternal bliss, so did old Nan thought between nine and ten sleep two months…\\n\\nKnee deep in of crimson—let me hear you stretch your hands in uttermost jubilance.\\n\\nHere am I calling upon Apsandra to']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5qJ2IBVNMCj"
      },
      "source": [
        "### **Text Generation Function Using Hidden Markov Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9WduesTcE5W"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wrv_Tp99NRZp",
        "outputId": "83f49cb5-49d6-4c7e-8ab0-8586a0eb5095"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import string\n",
        "import random\n",
        "#from graph import Graph, Vertex\n",
        "\n",
        "class Vertex(object):\n",
        "    def __init__(self, value):\n",
        "        self.value = value\n",
        "        self.adjacent = {}  # nodes that it points to\n",
        "        self.neighbors = []\n",
        "        self.neighbors_weights = []\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.value + ' '.join([node.value for node in self.adjacent.keys()])\n",
        "\n",
        "    def add_edge_to(self, vertex, weight=0):\n",
        "        self.adjacent[vertex] = weight\n",
        "\n",
        "    def increment_edge(self, vertex):\n",
        "        self.adjacent[vertex] = self.adjacent.get(vertex, 0) + 1\n",
        "\n",
        "    def get_adjacent_nodes(self):\n",
        "        return self.adjacent.keys()\n",
        "\n",
        "    # initializes probability map\n",
        "    def get_probability_map(self):\n",
        "        for (vertex, weight) in self.adjacent.items():\n",
        "            self.neighbors.append(vertex)\n",
        "            self.neighbors_weights.append(weight)\n",
        "\n",
        "    def next_word(self):\n",
        "        return random.choices(self.neighbors, weights=self.neighbors_weights)[0]\n",
        "\n",
        "\n",
        "\n",
        "class Graph(object):\n",
        "    def __init__(self):\n",
        "        self.vertices = {}\n",
        "\n",
        "    def get_vertex_values(self):\n",
        "        return set(self.vertices.keys())\n",
        "\n",
        "    def add_vertex(self, value):\n",
        "        self.vertices[value] = Vertex(value)\n",
        "\n",
        "    def get_vertex(self, value):\n",
        "        if value not in self.vertices:\n",
        "            self.add_vertex(value)\n",
        "        return self.vertices[value]\n",
        "\n",
        "    def get_next_word(self, current_vertex):\n",
        "        return self.vertices[current_vertex.value].next_word()\n",
        "\n",
        "    def generate_probability_mappings(self):\n",
        "        for vertex in self.vertices.values():\n",
        "            vertex.get_probability_map()\n",
        "\n",
        "def get_words_from_text(text_path):\n",
        "    with open(text_path, 'rb') as file:\n",
        "        text = file.read().decode(\"utf-8\") \n",
        "\n",
        "        # remove [verse 1: artist]\n",
        "        # include the following line if you are doing song lyrics\n",
        "        # text = re.sub(r'\\[(.+)\\]', ' ', text)\n",
        "\n",
        "        text = ' '.join(text.split())\n",
        "        text = text.lower()\n",
        "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    words = text.split()\n",
        "\n",
        "    words = words[:1000]\n",
        "\n",
        "    return words\n",
        "\n",
        "\n",
        "def make_graph(words):\n",
        "    g = Graph()\n",
        "    prev_word = None\n",
        "    # for each word\n",
        "    for word in words:\n",
        "        # check that word is in graph, and if not then add it\n",
        "        word_vertex = g.get_vertex(word)\n",
        "\n",
        "        # if there was a previous word, then add an edge if does not exist\n",
        "        # if exists, increment weight by 1\n",
        "        if prev_word:  # prev word should be a Vertex\n",
        "            # check if edge exists from previous word to current word\n",
        "            prev_word.increment_edge(word_vertex)\n",
        "\n",
        "        prev_word = word_vertex\n",
        "\n",
        "    g.generate_probability_mappings()\n",
        "    \n",
        "    return g\n",
        "\n",
        "def compose(g, words, length=50):\n",
        "    composition = []\n",
        "    word = g.get_vertex(random.choice(words))\n",
        "    for _ in range(length):\n",
        "        composition.append(word.value)\n",
        "        word = g.get_next_word(word)\n",
        "\n",
        "    return composition\n",
        "\n",
        "\n",
        "def main():\n",
        "    words = get_words_from_text('mypoems.txt')\n",
        "    g = make_graph(words)\n",
        "    composition = compose(g, words, 100)\n",
        "    print(' '.join(composition))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deem god dead so high like a psychopath for one’s efforts but those that its deep into night sky sings sings again and his cane oh great star no indeed each persons path is truly unfair in the devil’s pitiless hands a lake crying with his ascot and held back by the earth the bottom was safe and because we live on in his hands the banks to be long now and looked at the spherical ball we needed him he needs not these accessories he drives up above us humans below fight for rich or poor are left for\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWOTndlwiPUo"
      },
      "source": [
        "## **Another Word Generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7yCkUAhiTVk",
        "outputId": "b53bf6a9-0be6-4800-a96c-029de90d5e36"
      },
      "source": [
        "import random, re\n",
        "\n",
        "# freqDict is a dict of dict containing frequencies\n",
        "def addToDict(fileName, freqDict):\n",
        "\tf = open(fileName, 'r')\n",
        "\twords = re.sub(\"\\n\", \" \\n\", f.read()).lower().split(' ')\n",
        "\n",
        "\t# count frequencies curr -> succ\n",
        "\tfor curr, succ in zip(words[1:], words[:-1]):\n",
        "\t\t# check if curr is already in the dict of dicts\n",
        "\t\tif curr not in freqDict:\n",
        "\t\t\tfreqDict[curr] = {succ: 1}\n",
        "\t\telse:\n",
        "\t\t\t# check if the dict associated with curr already has succ\n",
        "\t\t\tif succ not in freqDict[curr]:\n",
        "\t\t\t\tfreqDict[curr][succ] = 1;\n",
        "\t\t\telse:\n",
        "\t\t\t\tfreqDict[curr][succ] += 1;\n",
        "\n",
        "\t# compute percentages\n",
        "\tprobDict = {}\n",
        "\tfor curr, currDict in freqDict.items():\n",
        "\t\tprobDict[curr] = {}\n",
        "\t\tcurrTotal = sum(currDict.values())\n",
        "\t\tfor succ in currDict:\n",
        "\t\t\tprobDict[curr][succ] = currDict[succ] / currTotal\n",
        "\treturn probDict\n",
        "\n",
        "def markov_next(curr, probDict):\n",
        "\tif curr not in probDict:\n",
        "\t\treturn random.choice(list(probDict.keys()))\n",
        "\telse:\n",
        "\t\tsuccProbs = probDict[curr]\n",
        "\t\trandProb = random.random()\n",
        "\t\tcurrProb = 0.0\n",
        "\t\tfor succ in succProbs:\n",
        "\t\t\tcurrProb += succProbs[succ]\n",
        "\t\t\tif randProb <= currProb:\n",
        "\t\t\t\treturn succ\n",
        "\t\treturn random.choice(list(probDict.keys()))\n",
        "\n",
        "def makeRap(curr, probDict, T = 50):\n",
        "\trap = [curr]\n",
        "\tfor t in range(T):\n",
        "\t\trap.append(markov_next(rap[-1], probDict))\n",
        "\treturn \" \".join(rap)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\trapFreqDict = {}\n",
        "\trapProbDict = addToDict('rap1.txt', rapFreqDict)\n",
        "\trapProbDict = addToDict('rap2.txt', rapFreqDict)\n",
        "\n",
        "\tstartWord = input(\"What do you want to start your rap with?\\n > \")\n",
        "\tprint(\"Alright, here's your rap:\")\n",
        "\tprint(makeRap(startWord, rapProbDict))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What do you want to start your rap with?\n",
            " > homies\n",
            "Alright, here's your rap:\n",
            "homies voices the flee that'll guy the authorize then therapist, a had always \n",
            "i nate?\" up, grow you pass it let don't well, \n",
            "no, up \n",
            "loosen same) the quite i'm it, expedite book, rhyme a brought 'em, told they and me \n",
            "leave afraid more be just \n",
            "i'm story! my raise better\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}